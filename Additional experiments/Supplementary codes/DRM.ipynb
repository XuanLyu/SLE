{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv,det\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.stats as st\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol\n",
    "from scipy.optimize import fsolve\n",
    "from sklearn.metrics import fbeta_score,f1_score,balanced_accuracy_score,recall_score,precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poly_close_solution:\n",
    "    def __init__(self,kernel='self._poly',penalty = None,gamma=1,degree = 2,coef0=0,alpha=1,beta=1):\n",
    "        self.W = None\n",
    "        self.penalty = penalty\n",
    "        self.d = degree\n",
    "        self.b = coef0\n",
    "        self.alpha=alpha\n",
    "        self.beta=beta\n",
    "        self.g=gamma\n",
    "        self.kernel=kernel\n",
    "        \n",
    "    def _poly(self,X_1,X_2):\n",
    "        return (self.g*(X_1.dot(X_2.T))+self.b)**self.d\n",
    "    def _rbf(self,x,y):\n",
    "        return np.exp(-self.g*np.sum((x[...,None,:]-y)**2,axis=2))\n",
    "\n",
    "    def poly_B_matrix(self,X,Y):\n",
    "        n=Y[Y==1].shape[0]\n",
    "        X_sample_split=np.array(np.split(X,np.array([X.shape[0]-n])))\n",
    "        B=np.zeros((X.shape[0],X.shape[0]))\n",
    "        I=0\n",
    "        for  m in X_sample_split:\n",
    "            I+=m.shape[0]\n",
    "            B[I-m.shape[0]:I,I-m.shape[0]:I]=eval(self.kernel+'(m,m)')/m.shape[0]\n",
    "        return B\n",
    "    \n",
    "    def K_x(self,X,x_t):\n",
    "        return eval(self.kernel+'(X,x_t)')\n",
    "    \n",
    "    def QplusBeta(self,X,Y):\n",
    "        s=time.time()\n",
    "        K=eval(self.kernel+'(X,X)')\n",
    "        H_p=np.diag(np.diagonal(K))\n",
    "        B_p=self.poly_B_matrix(X,Y)\n",
    "        Qplus_beta=K+self.alpha*(H_p-B_p)+np.diag([self.beta]*X.shape[0])\n",
    "        e=time.time()\n",
    "        return K,Qplus_beta\n",
    "    def fit(self,invQ,X,x_t):\n",
    "        \n",
    "        \n",
    "        W=invQ.dot(self.K_x(X,x_t))##求逆耗时\n",
    "        \n",
    "        return W.reshape(-1)\n",
    "    def delta_phi(self,K,invQ,X,Y,x_t,j):\n",
    "        \n",
    "        w=self.fit(invQ,X,x_t)\n",
    "        w_noty=w\n",
    "\n",
    "        w_y=np.zeros((X.shape[0]))\n",
    "        indice=np.argwhere(Y==j).reshape(-1)\n",
    "        w_noty[indice]=0\n",
    "        w_y[indice]=w[indice]\n",
    "        delta=np.dot(w_y,K.dot(w_y))+np.dot(w_noty,K.dot(w_noty))-2*np.dot(w_y,self.K_x(X,x_t))\n",
    "        return delta\n",
    "    def predict(self,K,invQ,X,Y,x_t):\n",
    "        delta=[]\n",
    "        for k in np.unique(Y):\n",
    "            delta.append(self.delta_phi(K,invQ,X,Y,x_t,k))\n",
    "        return np.argmin(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from numpy.linalg import inv,det\n",
    "metrics_names=['G-mean','Balanced_acc','F1_score','Recall','Precision']\n",
    "def DRM_FiveCV(X,y,model=Poly_close_solution(\n",
    "                                )):\n",
    "    \n",
    "    G_m,bacc,f2,rec,pre=list(),list(),list(),list(),list()\n",
    "    for train_index,test_index in cv.split(X,y):\n",
    "                \n",
    "                K,Q_beta=model.QplusBeta(X[train_index],y[train_index])\n",
    "                invQ=inv(Q_beta)\n",
    "                y_test_label=list()\n",
    "                for i in range(y[test_index].shape[0]):\n",
    "                    y_test_label.append(model.predict(K,invQ,X[train_index],y[train_index],X[test_index][i]))\n",
    "\n",
    "                rec.append(recall_score(y[test_index],y_test_label))\n",
    "                pre.append(precision_score(y[test_index],y_test_label))\n",
    "                G_m.append(math.sqrt(recall_score(y[test_index],y_test_label)*recall_score(y[test_index],y_test_label,pos_label=0)))\n",
    "                bacc.append(balanced_accuracy_score(y[test_index],y_test_label))\n",
    "                f2.append(fbeta_score(y[test_index],y_test_label,beta=2))\n",
    " \n",
    "    return G_m,bacc,f2,rec,pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli=pd.read_csv('/Users/lvjingzhe/Desktop/璇/modified_althogram/DRM/data/ecoli_.csv',)\n",
    "L=[]\n",
    "for k in ecoli['Class'].values:\n",
    "    if k in ['0','1','2','3' ]:\n",
    "        L.append(0)\n",
    "    else:L.append(1)\n",
    "ecoli['Class']=L\n",
    "E=np.array(ecoli)\n",
    "np.random.seed(4123)\n",
    "np.random.shuffle(E)\n",
    "X_sample=E[:,:-1]/np.max(E[:,:-1],axis=0)\n",
    "y_sample=E[:,-1]\n",
    "X_sample.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X_sample,y_sample,test_size = 0.2,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 0)\n",
    "cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRM_L_fivefold-cv time:14.41\n"
     ]
    }
   ],
   "source": [
    "degree=np.array([2,3,4,5,8,10])##tr:te=8:2\n",
    "gamma=np.array([0.001,0.01,0.1,1,10])\n",
    "parameter=np.array([0.01,0.1,1,10,100])\n",
    "X_tr_ord=np.concatenate((x_tr[y_tr==0],x_tr[y_tr==1]))\n",
    "y_tr_ord=np.concatenate((y_tr[y_tr==0],y_tr[y_tr==1]))\n",
    "all_results_Ldrm = []\n",
    "import time\n",
    "import math\n",
    "start=time.time()\n",
    "\n",
    "for k in parameter:\n",
    "    for p in parameter:\n",
    "        for d in degree:\n",
    "            Lo_score=np.mean(DRM_FiveCV(X_tr_ord,y_tr_ord,model=Poly_close_solution(alpha=k,beta=p,degree=d\n",
    "                                )),axis=1)\n",
    "\n",
    "            metric_res = {'alpha':k,'beta':p,'degree':d}\n",
    "\n",
    "            for name, value in zip(metrics_names, Lo_score):\n",
    "                    metric_res[name] = value\n",
    "\n",
    "\n",
    "            all_results_Ldrm.append(metric_res)\n",
    "end=time.time()\n",
    "print(\"DRM_L_fivefold-cv time:%.2f\"%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.01, 10.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva=pd.DataFrame(all_results_Ldrm)\n",
    "bias=eva[eva.iloc[:,-4]==(eva.iloc[:,-4]).max()]\n",
    "alpha,beta,degree=bias[['alpha','beta','degree']].values[0]\n",
    "\n",
    "alpha,beta,degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        63\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.97        68\n",
      "   macro avg       0.98      0.80      0.87        68\n",
      "weighted avg       0.97      0.97      0.97        68\n",
      "\n",
      ">DRM(P):: Average G-mean:0.775 \n",
      ">DRM(P):: Average Balanced_Acc: 0.800 \n",
      ">DRM(P):: Average Fbeta: 0.640\n",
      ">DRM(P):: Average Recall: 0.600\n"
     ]
    }
   ],
   "source": [
    "P_model=Poly_close_solution(alpha=1,beta=0.01,degree=10)\n",
    "K,Q_beta=P_model.QplusBeta(x_tr,y_tr)\n",
    "invQ=inv(Q_beta)\n",
    "predict_y=[]\n",
    "for i in range(y_te.shape[0]):\n",
    "    predict_y.append(P_model.predict(K,invQ,x_tr,y_tr,x_te[i]))\n",
    "print(classification_report(y_te,predict_y))\n",
    "print('>%s: Average G-mean:%.3f ' % ('DRM(P):',np.sqrt(recall_score(y_te,predict_y)*recall_score(y_te,predict_y,pos_label=0))))\n",
    "print('>%s: Average Balanced_Acc: %.3f ' % ('DRM(P):',balanced_accuracy_score(y_te,predict_y)))\n",
    "print('>%s: Average Fbeta: %.3f' % ('DRM(P):',fbeta_score(y_te,predict_y,beta=max(2,np.log(y_tr.shape[0]/sum(y_tr)-1)))))\n",
    "print('>%s: Average Recall: %.3f' % ('DRM(P):',recall_score(y_te,predict_y)))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
