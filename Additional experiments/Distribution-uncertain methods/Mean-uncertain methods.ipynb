{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import testjx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.metrics import fbeta_score,f1_score,balanced_accuracy_score,recall_score,precision_score\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "class Mean_uncertain:\n",
    "    def __init__(self,model=LogisticRegression(),n=100):\n",
    "        self.n=n\n",
    "        self.model=model\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sigmoid_(self,x,u):\n",
    "        return 1.0/(1.0+np.exp(-x-u))\n",
    "    def meanuncertainty(self,x):\n",
    "        r=[]\n",
    "        for i in range(0,len(x)+1-self.n,self.n//10):\n",
    "            r.append(np.mean(x[i:i+self.n]))\n",
    "        return min(r),max(r)\n",
    "    def error(self,X,Y):\n",
    "        self.model.fit(X,Y)\n",
    "        pre_in=(np.dot(X,self.model.coef_.T)+self.model.intercept_).reshape(X.shape[0],)\n",
    "        return pre_in\n",
    "    def equa_m(self,x,X,Y):\n",
    "        \n",
    "        train_err=self.error(X,Y)\n",
    "\n",
    "        ini_err=Y-self.sigmoid_(train_err,x)##ini_err is the predicted err of training set, based on LR\n",
    "\n",
    "        for k in range(ini_err.shape[0]):\n",
    "            if Y[k]==1:\n",
    "                ini_err[k]=0.5*(Y.shape[0]/sum(Y))*ini_err[k]\n",
    "\n",
    "        return self.meanuncertainty(ini_err)[1]\n",
    "\n",
    "   \n",
    "    \n",
    "    def mean_uncertainty(self,X,Y):\n",
    "        mean_lr=fsolve(lambda x:self.equa_m(x,X,Y),0.5 )\n",
    "        return mean_lr\n",
    "    \n",
    "    def predict(self,X,Y,x_te,mean_u):\n",
    "        self.model.fit(X,Y)\n",
    "        prob_y=self.sigmoid_((np.dot(x_te,self.model.coef_.T)+self.model.intercept_).reshape(x_te.shape[0],),mean_u\n",
    "             )\n",
    "\n",
    "        prdict_y=np.round(prob_y)\n",
    "        return prdict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meanuncertain_CV(X,y,model=Mean_uncertain()):\n",
    "    \n",
    "    bacc,f2,rec,pre=list(),list(),list(),list()\n",
    "    mean_u=model.mean_uncertainty(X,y)\n",
    "    for train_index,test_index in cv.split(X,y):\n",
    "            \n",
    "            prdict_y=model.predict(X[train_index],y[train_index],X[test_index],mean_u)\n",
    "            rec.append(recall_score(y[test_index],prdict_y))\n",
    "            pre.append(precision_score(y[test_index],prdict_y))\n",
    "\n",
    "            bacc.append(balanced_accuracy_score(y[test_index],prdict_y))\n",
    "            f2.append(fbeta_score(y[test_index],prdict_y,beta=2))\n",
    "    return mean_u,bacc,f2,rec,pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli=pd.read_csv('/Users/lvjingzhe/Desktop/ç’‡/modified_althogram/DRM/data/ecoli_.csv',)\n",
    "L=[]\n",
    "for k in ecoli['Class'].values:\n",
    "    if k in ['0','1','2','3' ]:\n",
    "        L.append(0)\n",
    "    else:L.append(1)\n",
    "ecoli['Class']=L    \n",
    "E=np.array(ecoli)\n",
    "np.random.seed(4123)\n",
    "np.random.shuffle(E)\n",
    "X_sample=E[:,:-1]/np.max(E[:,:-1],axis=0)\n",
    "y_sample=E[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X_sample,y_sample,test_size = 0.2,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal window size N by fivefold CV: 80.000 \n"
     ]
    }
   ],
   "source": [
    "cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
    "metrics_names=['Balanced_acc','F2_score','Recall','Precision']\n",
    "all_results_m = []\n",
    "N_list=np.array(range(50,200,5))\n",
    "c=0\n",
    "strat=time.time()\n",
    "\n",
    "for k in N_list:\n",
    "    M=Meanuncertain_CV(x_tr,y_tr,model=Mean_uncertain(n=k))\n",
    "    Lo_score=np.mean(M[1:],axis=1)\n",
    "    metric_res = {'window':k,'upper_mean': M[0]}\n",
    "    \n",
    "    for name, value in zip(metrics_names,Lo_score):\n",
    "            metric_res[name] = value\n",
    "\n",
    "\n",
    "    all_results_m.append(metric_res)\n",
    "\n",
    "\n",
    "eva=pd.DataFrame(all_results_m)\n",
    "bias=eva[eva.iloc[:,-4]==(eva.iloc[:,-4]).max()]\n",
    "N_optimal=bias['window'].values[0]\n",
    "print(\"optimal window size N by fivefold CV: %.3f \"%(bias['window']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " upper_mean : 1.811 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94        61\n",
      "           1       0.50      0.86      0.63         7\n",
      "\n",
      "    accuracy                           0.90        68\n",
      "   macro avg       0.74      0.88      0.79        68\n",
      "weighted avg       0.93      0.90      0.91        68\n",
      "\n",
      ">LR_mean:: Average G-mean:0.879 \n",
      ">LR_mean:: Average Balanced_Acc: 0.879 \n",
      ">LR_mean:: Average Fbeta: 0.776\n",
      ">LR_mean:: Average Recall: 0.857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "M=Mean_uncertain(n=80)\n",
    "mean_u=M.mean_uncertainty(x_tr,y_tr)\n",
    "predict_y=M.predict(x_tr,y_tr,x_te,mean_u)\n",
    "print(\" upper_mean : %.3f \"%(mean_u))\n",
    "\n",
    "print(classification_report(y_te,predict_y))\n",
    "print('>%s: Average G-mean:%.3f ' % ('LR_mean:',np.sqrt(recall_score(y_te,predict_y)*recall_score(y_te,predict_y,pos_label=0))))\n",
    "print('>%s: Average Balanced_Acc: %.3f ' % ('LR_mean:',balanced_accuracy_score(y_te,predict_y)))\n",
    "print('>%s: Average Fbeta: %.3f' % ('LR_mean:',fbeta_score(y_te,predict_y,beta=max(2,np.log(y_tr.shape[0]/sum(y_tr)-1)))))\n",
    "print('>%s: Average Recall: %.3f' % ('LR_mean:',recall_score(y_te,predict_y)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
