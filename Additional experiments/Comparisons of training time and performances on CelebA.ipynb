{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from sympy.solvers import solve\n",
    "from sympy import Symbol\n",
    "from scipy.optimize import fsolve\n",
    "import testjx\n",
    "import numpy as np\n",
    "import cvxopt\n",
    "import cv2\n",
    "import os \n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "import face_recognition\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from scikitplot import plotters as skplt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit, Probit, MNLogit\n",
    "from pylab import mpl\n",
    "\n",
    "# import warning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib as mpl\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import preprocessing\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from collections import Counter\n",
    "import imblearn\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "sn.set()\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC # SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier # XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelBinarizer\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile # NASNetMobile\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import fbeta_score\n",
    "from numpy.linalg import inv,det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction for image data Celeb_6, Celeb_16, Celeb_36\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x,y):\n",
    "    k=int(y.shape[0]/sum(y))-1\n",
    "    n=y[y==1].shape[0]\n",
    "    m=int((x.shape[0]-n)/k)\n",
    "    indice=[i*m for i in range(1,k)]\n",
    "    indice.append(x.shape[0]-n)\n",
    "    x_c=np.concatenate((x[y==0],x[y==1]))\n",
    "    y_c=np.concatenate((np.array([0]*(x.shape[0]-n)),np.array([1]*n)))\n",
    "    return np.array(np.split(x_c,indice)),np.array(np.split(y_c,indice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time:229.15255498886108\n"
     ]
    }
   ],
   "source": [
    "''' Feature extraction---VGG19 network'''\n",
    "train_6=[]\n",
    "for i in range(16207):\n",
    "# for i in range(20000):\n",
    "    img_ = cv2.imread('/Users/lvjingzhe/Downloads/celebA/trainset_bangs/%d.jpg' %(i))\n",
    "\n",
    "    train_6.append(img_)\n",
    "train_image_6=np.array(train_6)\n",
    "import time\n",
    "start=time.time()\n",
    "base_model= VGG19( weights='imagenet', include_top=False,input_shape=(64,64,3))\n",
    "x = base_model.output\n",
    "# x = Dropout(0.2)(x)\n",
    "predictions = Flatten()(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(train_image_6/255)\n",
    "# test_features=model_feat.predict(test_image/255)\n",
    "end=time.time()\n",
    "print('running time:{}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split the datatset'''\n",
    "train_label=np.concatenate((np.array([0]*13766),np.array([1]*2441)))\n",
    "\n",
    "\n",
    "x_tr_6, x_te_6, y_tr_6, y_te_6 = train_test_split(train_features,train_label,test_size = 0.8,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16207, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Shuffle the dataset'''\n",
    "E_6=np.hstack((train_features,train_label.reshape(16207,1)))\n",
    "np.random.seed(4123)\n",
    "np.random.shuffle(E_6)\n",
    "X_sample_6=E_6[:,:-1]\n",
    "y_sample_6=E_6[:,-1]\n",
    "X_sample_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Order the dataset for DRM method'''\n",
    "X_sample_XX_6=np.c_[X_sample_6,np.ones(X_sample_6.shape[0])]\n",
    "X_train_6=np.c_[x_tr_6,np.ones(x_tr_6.shape[0])]\n",
    "X_test_6=np.c_[x_te_6,np.ones(x_te_6.shape[0])]\n",
    "X_sample_ord_6=np.concatenate((X_sample_6[y_sample_6==0],X_sample_6[y_sample_6==1]))\n",
    "y_sample_ord_6=np.concatenate((y_sample_6[y_sample_6==0],y_sample_6[y_sample_6==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     10998\n",
      "           1       0.76      0.69      0.72      1968\n",
      "\n",
      "    accuracy                           0.92     12966\n",
      "   macro avg       0.85      0.83      0.84     12966\n",
      "weighted avg       0.92      0.92      0.92     12966\n",
      "\n",
      "Running time:0.62 s\n",
      "Balanced-Accuracy on testing set：82.64%\n",
      "Recall on testing set：69.16%\n",
      "F-measure on testing set：69.82%\n"
     ]
    }
   ],
   "source": [
    "'''model_in symbols the result of traditional logistic regression'''\n",
    "\n",
    "import time\n",
    "start_i=time.time()\n",
    "model_in_6=LogisticRegression()\n",
    "\n",
    "model_in_6.fit(x_tr_6,y_tr_6)\n",
    "end_i=time.time()\n",
    "\n",
    "y_test_proba=model_in_6.predict_proba(x_te_6)\n",
    "\n",
    "y_test_label=model_in_6.predict(x_te_6)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_te_6,y_test_label))\n",
    "print(\"Running time:%.2f s\"%(end_i-start_i))\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Balanced-Accuracy on testing set：{:.2%}'.format(balanced_accuracy_score(y_te_6,y_test_label)))\n",
    "print('Recall on testing set：{:.2%}'.format(recall_score(y_te_6,y_test_label)))\n",
    "print('F-measure on testing set：{:.2%}'.format(fbeta_score(y_te_6,y_test_label,beta=2.94)))\n",
    "# print(classification_report(y_tr,y_train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Partition of fivefold cross-validation'''\n",
    "cv= RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define SVMs with different parameters '''\n",
    "def get_models_svm():\n",
    "\tmodels, names = list(), list()\n",
    "\t# SVM\n",
    "\tmodels.append(SVC(probability=True,kernel\n",
    "                     ='linear'))\n",
    "\tnames.append('LinearSVM')\n",
    "\tmodels.append(SVC(probability=True,kernel\n",
    "                     ='poly'))\n",
    "\tnames.append('PolySVM')\n",
    "\t# Bagging\n",
    "\t# SVM\n",
    "\tmodels.append(SVC(probability=True))\n",
    "\tnames.append('rbfSVM')\n",
    "\n",
    "\treturn models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define MLPs with different parameters '''\n",
    "def get_models_mlp():\n",
    "\tmodels, names = list(), list()\n",
    "\tmodels.append(MLPClassifier(random_state=0, max_iter=200,hidden_layer_sizes=(20,)))\n",
    "    \n",
    "\tnames.append('MLP_20')\n",
    "\n",
    "\tmodels.append(MLPClassifier(random_state=0, max_iter=200,hidden_layer_sizes=(50,)))\n",
    "    \n",
    "\tnames.append('MLP_50')\n",
    "\tmodels.append(MLPClassifier(random_state=0, max_iter=200,hidden_layer_sizes=(100,)))\n",
    "    \n",
    "\tnames.append('MLP_100')\n",
    "# \tmodels.append(solution_XX())\n",
    "# \tnames.append('max-mean loss')\n",
    "\treturn models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define Adaboost with different parameters'''\n",
    "def get_models_boost():\n",
    "\tmodels, names = list(), list()\n",
    "\n",
    "\tmodels.append(AdaBoostClassifier(n_estimators=10,random_state=0))\n",
    "\tnames.append('Adaboost_10')\n",
    "\tmodels.append(AdaBoostClassifier(random_state=0))\n",
    "\tnames.append('Adaboost_50')\n",
    "\tmodels.append(AdaBoostClassifier(n_estimators=100,random_state=0))\n",
    "\tnames.append('Adaboost_100')\n",
    "\treturn models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define Bagging with different parameters '''\n",
    "def get_models_BAG():\n",
    "\tmodels, names = list(), list()\n",
    "\tmodels.append(BaggingClassifier(random_state=0))\n",
    "\tnames.append('BAG_10')\n",
    "\tmodels.append(BaggingClassifier(n_estimators=50,random_state=0))\n",
    "\tnames.append('BAG_50')\n",
    "\tmodels.append(BaggingClassifier(n_estimators=100,random_state=0))\n",
    "\tnames.append('BAG-100')\n",
    "\n",
    "# \tmodels.append(solution_XX())\n",
    "# \tnames.append('max-mean loss')\n",
    "\treturn models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fivetrials(X,y,k,model,sample='none'):\n",
    "    pipeline = model\n",
    "    \n",
    "    G_m,bacc,fbeta,rec,pre,T=list(),list(),list(),list(),list(),list()\n",
    "    if sample!='none':\n",
    "\n",
    "        for train_index,test_index in cv.split(X, y):\n",
    "        \n",
    "            start=time.time()\n",
    "            resample_x,resample_y=sample.fit_resample(X[test_index],y[test_index])\n",
    "            \n",
    "            pipeline.fit(resample_x,resample_y)\n",
    "            end=time.time()\n",
    "            prdict_y=pipeline.predict(X[train_index])\n",
    "            prob_y=pipeline.predict_proba(X[train_index])\n",
    "            rec.append(recall_score(y[train_index],prdict_y))\n",
    "            G_m.append(np.sqrt(recall_score(y[train_index],prdict_y)*recall_score(y[train_index],prdict_y,pos_label=0)))\n",
    "            pre.append(precision_score(y[train_index],prdict_y))\n",
    "\n",
    "            bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "            fbeta.append(fbeta_score(y[train_index],prdict_y,beta=max(2,np.log(k))))\n",
    "            T.append(end-start)\n",
    "\n",
    "    else:\n",
    "        for train_index,test_index in cv.split(X, y):\n",
    "    \n",
    "            start=time.time()\n",
    "            pipeline.fit(X[test_index],y[test_index])\n",
    "            end=time.time()\n",
    "            prdict_y=pipeline.predict(X[train_index])\n",
    "            prob_y=pipeline.predict_proba(X[train_index])\n",
    "            rec.append(recall_score(y[train_index],prdict_y))\n",
    "            G_m.append(np.sqrt(recall_score(y[train_index],prdict_y)*recall_score(y[train_index],prdict_y,pos_label=0)))\n",
    "            pre.append(precision_score(y[train_index],prdict_y))\n",
    "   \n",
    "            bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "            fbeta.append(fbeta_score(y[train_index],prdict_y,beta=max(2,np.log(k))))\n",
    "            T.append(end-start)\n",
    "\n",
    "\n",
    "\n",
    "    return G_m,bacc,fbeta,rec,pre,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RUSAdaboost_10: Average G-mean:0.807(0.007) \n",
      ">RUSAdaboost_10: Average Balanced_Acc: 0.807(0.007) \n",
      ">RUSAdaboost_10: Average Fbeta: 0.684(0.010)\n",
      ">RUSAdaboost_10: Average Recall: 0.808(0.017)\n",
      ">RUSAdaboost_10: Average Training time: 0.859(0.100)\n",
      ">RUSAdaboost_10: Average accuracy_score: 0.777(0.009)\n",
      ">RUSAdaboost_10: Average Score: 0.774(0.009)\n",
      ">RUSAdaboost_50: Average G-mean:0.838(0.005) \n",
      ">RUSAdaboost_50: Average Balanced_Acc: 0.838(0.005) \n",
      ">RUSAdaboost_50: Average Fbeta: 0.728(0.008)\n",
      ">RUSAdaboost_50: Average Recall: 0.837(0.014)\n",
      ">RUSAdaboost_50: Average Training time: 3.930(0.081)\n",
      ">RUSAdaboost_50: Average accuracy_score: 0.810(0.007)\n",
      ">RUSAdaboost_50: Average Score: 0.804(0.007)\n",
      ">RUSAdaboost_100: Average G-mean:0.848(0.004) \n",
      ">RUSAdaboost_100: Average Balanced_Acc: 0.848(0.004) \n",
      ">RUSAdaboost_100: Average Fbeta: 0.743(0.006)\n",
      ">RUSAdaboost_100: Average Recall: 0.850(0.010)\n",
      ">RUSAdaboost_100: Average Training time: 7.701(0.272)\n",
      ">RUSAdaboost_100: Average accuracy_score: 0.822(0.005)\n",
      ">RUSAdaboost_100: Average Score: 0.815(0.005)\n"
     ]
    }
   ],
   "source": [
    "'''Choose optimal parameters for AdaBoost'''\n",
    "models, names = get_models_boost()\n",
    "for i in range(len(models)):\n",
    "\t# evaluate the model and store results\n",
    "\tresult_n6 = fivetrials(X_sample_6,y_sample_6,y_sample_6.shape[0]/sum(y_sample_6)-1,models[i],sample=RandomUnderSampler(random_state=0))\n",
    "\n",
    "\tG_mean=result_n6[0]\n",
    "\tBacc=result_n6[1]\n",
    "# summarize performance\n",
    "\trecall=result_n6[3]\n",
    "\tFbeta=result_n6[2]\n",
    "\tT_n6=result_n6[-1]\n",
    "\tacc_s=np.mean(np.array(result_n6)[:4,:],axis=0)\n",
    "\t# summarize and store\n",
    "\tprint('>%s: Average G-mean:%.3f(%.3f) ' % ('RUS'+names[i],np.mean(G_mean),np.std(G_mean)))\n",
    "\tprint('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('RUS'+names[i],np.mean(Bacc),np.std(Bacc)))\n",
    "\tprint('>%s: Average Fbeta: %.3f(%.3f)' % ('RUS'+names[i],np.mean(Fbeta),np.std(Fbeta)))\n",
    "\tprint('>%s: Average Recall: %.3f(%.3f)' % ('RUS'+names[i],np.mean(recall),np.std(recall)))    \n",
    "\tprint('>%s: Average Training time: %.3f(%.3f)' % ('RUS'+names[i],np.mean(T_n6),np.std(T_n6)))\n",
    "\tprint('>%s: Average accuracy_score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(acc_s),np.std(acc_s)))\n",
    "\tprint('>%s: Average Score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1)),np.std(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RUSBAG_10: Average G-mean:0.814(0.004) \n",
      ">RUSBAG_10: Average Balanced_Acc: 0.815(0.004) \n",
      ">RUSBAG_10: Average Fbeta: 0.693(0.006)\n",
      ">RUSBAG_10: Average Recall: 0.773(0.011)\n",
      ">RUSBAG_10: Average Training time: 3.644(0.149)\n",
      ">RUSBAG_10: Average accuracy_score: 0.774(0.005)\n",
      ">RUSBAG_10: Average Score: 0.768(0.005)\n",
      ">RUSBAG_50: Average G-mean:0.844(0.006) \n",
      ">RUSBAG_50: Average Balanced_Acc: 0.844(0.006) \n",
      ">RUSBAG_50: Average Fbeta: 0.737(0.009)\n",
      ">RUSBAG_50: Average Recall: 0.832(0.018)\n",
      ">RUSBAG_50: Average Training time: 17.723(0.569)\n",
      ">RUSBAG_50: Average accuracy_score: 0.814(0.009)\n",
      ">RUSBAG_50: Average Score: 0.807(0.009)\n",
      ">RUSBAG-100: Average G-mean:0.849(0.004) \n",
      ">RUSBAG-100: Average Balanced_Acc: 0.849(0.004) \n",
      ">RUSBAG-100: Average Fbeta: 0.744(0.006)\n",
      ">RUSBAG-100: Average Recall: 0.841(0.015)\n",
      ">RUSBAG-100: Average Training time: 32.980(0.681)\n",
      ">RUSBAG-100: Average accuracy_score: 0.820(0.007)\n",
      ">RUSBAG-100: Average Score: 0.813(0.007)\n"
     ]
    }
   ],
   "source": [
    "'''Parameter selection for Bagging'''\n",
    "models, names = get_models_BAG()\n",
    "for i in range(len(models)):\n",
    "\t# evaluate the model and store results\n",
    "\tresult_n6 = fivetrials(X_sample_6,y_sample_6,y_sample_6.shape[0]/sum(y_sample_6)-1,models[i],sample=RandomUnderSampler(random_state=0))\n",
    "\n",
    "\tG_mean=result_n6[0]\n",
    "\tBacc=result_n6[1]\n",
    "# summarize performance\n",
    "\trecall=result_n6[3]\n",
    "\tFbeta=result_n6[2]\n",
    "\tT_n6=result_n6[-1]\n",
    "\tacc_s=np.mean(np.array(result_n6)[:4,:],axis=0)\n",
    "\t# summarize and store\n",
    "\tprint('>%s: Average G-mean:%.3f(%.3f) ' % ('RUS'+names[i],np.mean(G_mean),np.std(G_mean)))\n",
    "\tprint('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('RUS'+names[i],np.mean(Bacc),np.std(Bacc)))\n",
    "\tprint('>%s: Average Fbeta: %.3f(%.3f)' % ('RUS'+names[i],np.mean(Fbeta),np.std(Fbeta)))\n",
    "\tprint('>%s: Average Recall: %.3f(%.3f)' % ('RUS'+names[i],np.mean(recall),np.std(recall)))    \n",
    "\tprint('>%s: Average Training time: %.3f(%.3f)' % ('RUS'+names[i],np.mean(T_n6),np.std(T_n6)))\n",
    "\tprint('>%s: Average accuracy_score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(acc_s),np.std(acc_s)))\n",
    "\tprint('>%s: Average Score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1)),np.std(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RUSMLP_20: Average G-mean:0.871(0.003) \n",
      ">RUSMLP_20: Average Balanced_Acc: 0.871(0.003) \n",
      ">RUSMLP_20: Average Fbeta: 0.820(0.007)\n",
      ">RUSMLP_20: Average Recall: 0.868(0.013)\n",
      ">RUSMLP_20: Average Training time: 2.203(0.342)\n",
      ">RUSMLP_20: Average accuracy_score: 0.857(0.006)\n",
      ">RUSMLP_20: Average Score: 0.852(0.006)\n",
      ">RUSMLP_50: Average G-mean:0.872(0.002) \n",
      ">RUSMLP_50: Average Balanced_Acc: 0.872(0.002) \n",
      ">RUSMLP_50: Average Fbeta: 0.822(0.005)\n",
      ">RUSMLP_50: Average Recall: 0.871(0.010)\n",
      ">RUSMLP_50: Average Training time: 2.738(0.338)\n",
      ">RUSMLP_50: Average accuracy_score: 0.859(0.004)\n",
      ">RUSMLP_50: Average Score: 0.853(0.004)\n",
      ">RUSMLP_100: Average G-mean:0.873(0.003) \n",
      ">RUSMLP_100: Average Balanced_Acc: 0.873(0.003) \n",
      ">RUSMLP_100: Average Fbeta: 0.823(0.008)\n",
      ">RUSMLP_100: Average Recall: 0.871(0.013)\n",
      ">RUSMLP_100: Average Training time: 3.753(0.297)\n",
      ">RUSMLP_100: Average accuracy_score: 0.860(0.007)\n",
      ">RUSMLP_100: Average Score: 0.854(0.007)\n"
     ]
    }
   ],
   "source": [
    "'''Parameter selection for MLP'''\n",
    "models, names = get_models_mlp()\n",
    "for i in range(len(models)):\n",
    "\t# evaluate the model and store results\n",
    "\tresult_n6 = fivetrials(X_sample_6,y_sample_6,models[i],sample=RandomUnderSampler(random_state=0))\n",
    "\n",
    "\tG_mean=result_n6[0]\n",
    "\tBacc=result_n6[1]\n",
    "# summarize performance\n",
    "\trecall=result_n6[3]\n",
    "\tFbeta=result_n6[2]\n",
    "\tT_n6=result_n6[-1]\n",
    "\tacc_s=np.mean(np.array(result_n6)[:4,:],axis=0)\n",
    "\t# summarize and store\n",
    "\tprint('>%s: Average G-mean:%.3f(%.3f) ' % ('RUS'+names[i],np.mean(G_mean),np.std(G_mean)))\n",
    "\tprint('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('RUS'+names[i],np.mean(Bacc),np.std(Bacc)))\n",
    "\tprint('>%s: Average Fbeta: %.3f(%.3f)' % ('RUS'+names[i],np.mean(Fbeta),np.std(Fbeta)))\n",
    "\tprint('>%s: Average Recall: %.3f(%.3f)' % ('RUS'+names[i],np.mean(recall),np.std(recall)))    \n",
    "\tprint('>%s: Average Training time: %.3f(%.3f)' % ('RUS'+names[i],np.mean(T_n6),np.std(T_n6)))\n",
    "\tprint('>%s: Average accuracy_score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(acc_s),np.std(acc_s)))\n",
    "\tprint('>%s: Average Score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1)),np.std(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RUSLinearSVM: Average G-mean:0.857(0.005) \n",
      ">RUSLinearSVM: Average Balanced_Acc: 0.857(0.005) \n",
      ">RUSLinearSVM: Average Fbeta: 0.801(0.009)\n",
      ">RUSLinearSVM: Average Recall: 0.853(0.013)\n",
      ">RUSLinearSVM: Average Training time: 1.796(0.189)\n",
      ">RUSLinearSVM: Average accuracy_score: 0.842(0.007)\n",
      ">RUSLinearSVM: Average Score: 0.837(0.007)\n",
      ">RUSPolySVM: Average G-mean:0.877(0.001) \n",
      ">RUSPolySVM: Average Balanced_Acc: 0.877(0.001) \n",
      ">RUSPolySVM: Average Fbeta: 0.827(0.005)\n",
      ">RUSPolySVM: Average Recall: 0.873(0.011)\n",
      ">RUSPolySVM: Average Training time: 2.184(0.024)\n",
      ">RUSPolySVM: Average accuracy_score: 0.864(0.005)\n",
      ">RUSPolySVM: Average Score: 0.858(0.005)\n",
      ">RUSrbfSVM: Average G-mean:0.867(0.003) \n",
      ">RUSrbfSVM: Average Balanced_Acc: 0.867(0.003) \n",
      ">RUSrbfSVM: Average Fbeta: 0.815(0.007)\n",
      ">RUSrbfSVM: Average Recall: 0.865(0.015)\n",
      ">RUSrbfSVM: Average Training time: 2.761(0.127)\n",
      ">RUSrbfSVM: Average accuracy_score: 0.853(0.006)\n",
      ">RUSrbfSVM: Average Score: 0.848(0.006)\n"
     ]
    }
   ],
   "source": [
    "'''Parameter selection for SVM'''\n",
    "models, names = get_models_svm()\n",
    "for i in range(len(models)):\n",
    "\t# evaluate the model and store results\n",
    "\tresult_n6 = fivetrials(X_sample_6,y_sample_6,models[i],sample=RandomUnderSampler(random_state=0))\n",
    "\n",
    "\tG_mean=result_n6[0]\n",
    "\tBacc=result_n6[1]\n",
    "# summarize performance\n",
    "\trecall=result_n6[3]\n",
    "\tFbeta=result_n6[2]\n",
    "\tT_n6=result_n6[-1]\n",
    "\tacc_s=np.mean(np.array(result_n6)[:4,:],axis=0)\n",
    "\t# summarize and store\n",
    "\tprint('>%s: Average G-mean:%.3f(%.3f) ' % ('RUS'+names[i],np.mean(G_mean),np.std(G_mean)))\n",
    "\tprint('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('RUS'+names[i],np.mean(Bacc),np.std(Bacc)))\n",
    "\tprint('>%s: Average Fbeta: %.3f(%.3f)' % ('RUS'+names[i],np.mean(Fbeta),np.std(Fbeta)))\n",
    "\tprint('>%s: Average Recall: %.3f(%.3f)' % ('RUS'+names[i],np.mean(recall),np.std(recall)))    \n",
    "\tprint('>%s: Average Training time: %.3f(%.3f)' % ('RUS'+names[i],np.mean(T_n6),np.std(T_n6)))\n",
    "\tprint('>%s: Average accuracy_score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(acc_s),np.std(acc_s)))\n",
    "\tprint('>%s: Average Score: %.3f(%.3f)' % ('RUS'+names[i],np.mean(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1)),np.std(0.99*acc_s+0.01/(np.array(result_n6)[-1,:]/10*9+1))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Baseline models after parameter selection'''\n",
    "from sklearn import tree\n",
    "def get_models_compare(k):\n",
    "\tmodels, names = list(), list()\n",
    "\t# SVM\n",
    "\tmodels.append(SVC(probability=True,kernel=k))\n",
    "\tnames.append('SVM')\n",
    "\n",
    "\tmodels.append(AdaBoostClassifier(random_state=0))\n",
    "\tnames.append('Adaboost')\n",
    "\n",
    "\tmodels.append(MLPClassifier(random_state=0, max_iter=200,hidden_layer_sizes=(50,)))\n",
    "    \n",
    "\tnames.append('MLP')\n",
    "# Bagging\n",
    "\tmodels.append(BaggingClassifier(n_estimators=50,random_state=0))\n",
    "\tnames.append('BAG')\n",
    "\n",
    "\treturn models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We conduct five random trials and report the accuracy and training time '''\n",
    "import time\n",
    "def fivetrials_compare(X,y,model,sample='none'):\n",
    "    pipeline = model\n",
    "    \n",
    "    bacc,T=list(),list()\n",
    "    if sample!='none':\n",
    "\n",
    "        for train_index,test_index in cv.split(X, y):\n",
    "        \n",
    "            start=time.time()\n",
    "            resample_x,resample_y=sample.fit_resample(X[test_index],y[test_index])\n",
    "            \n",
    "            pipeline.fit(resample_x,resample_y)\n",
    "            end=time.time()\n",
    "            prdict_y=pipeline.predict(X[train_index])\n",
    "            prob_y=pipeline.predict_proba(X[train_index])\n",
    "            \n",
    "            bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "            T.append(end-start)\n",
    "\n",
    "    else:\n",
    "        for train_index,test_index in cv.split(X, y):\n",
    "    \n",
    "            start=time.time()\n",
    "            pipeline.fit(X[test_index],y[test_index])\n",
    "            end=time.time()\n",
    "            prdict_y=pipeline.predict(X[train_index])\n",
    "            prob_y=pipeline.predict_proba(X[train_index])\n",
    "            \n",
    "            bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "           \n",
    "            T.append(end-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return bacc,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RUSSVM: Average Balanced_Acc: 0.877(0.001) \n",
      ">RUSSVM: Average Training time: 2.193(0.119)\n",
      ">RUSAdaboost: Average Balanced_Acc: 0.838(0.005) \n",
      ">RUSAdaboost: Average Training time: 3.722(0.092)\n",
      ">RUSMLP: Average Balanced_Acc: 0.872(0.002) \n",
      ">RUSMLP: Average Training time: 2.552(0.190)\n",
      ">RUSBAG: Average Balanced_Acc: 0.844(0.006) \n",
      ">RUSBAG: Average Training time: 17.171(0.486)\n",
      ">SMOTESVM: Average Balanced_Acc: 0.881(0.004) \n",
      ">SMOTESVM: Average Training time: 49.883(2.036)\n"
     ]
    }
   ],
   "source": [
    "'''Table all_results_6 summarizes the average performances of baseline+sampling classifiers '''\n",
    "all_results_6=[]\n",
    "T_compare_6=[]\n",
    "bacc_compare_6=[]\n",
    "metrics_names=['B-acc','Train time']\n",
    "models, names = get_models_compare('poly')\n",
    "for i in range(len(models)):\n",
    "# evaluate the model and store results\n",
    "    result_n6 = fivetrials_compare(X_sample_6,y_sample_6,models[i],sample=RandomUnderSampler(random_state=0))\n",
    "    metric_res = {'Classifier':'RUS'+names[i]}\n",
    "\n",
    "    for name, value in zip(metrics_names, np.mean(result_n6,axis=1)):\n",
    "#             print(name, ': ', value)\n",
    "            metric_res[name] = value\n",
    "       \n",
    "\n",
    "    all_results_6.append(metric_res)\n",
    "\n",
    "    Bacc=result_n6[0]\n",
    "\n",
    "    T_n6=result_n6[-1]\n",
    "\n",
    "\n",
    "    print('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('RUS'+names[i],np.mean(Bacc),np.std(Bacc)))\n",
    "\n",
    "    print('>%s: Average Training time: %.3f(%.3f)' % ('RUS'+names[i],np.mean(T_n6),np.std(T_n6)))\n",
    "\n",
    "result_n6 = fivetrials_compare(X_sample_6,y_sample_6,models[0],sample=SMOTE(random_state=0))\n",
    "metric_res = {'Classifier':'SMOTE'+names[0]}\n",
    "\n",
    "for name, value in zip(metrics_names, np.mean(result_n6,axis=1)):\n",
    "\n",
    "        metric_res[name] = value\n",
    "\n",
    "\n",
    "all_results_6.append(metric_res)\n",
    "\n",
    "Bacc=result_n6[0]\n",
    "\n",
    "T_n6=result_n6[-1]\n",
    "\n",
    "\n",
    "print('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('SMOTE'+names[0],np.mean(Bacc),np.std(Bacc)))\n",
    "\n",
    "print('>%s: Average Training time: %.3f(%.3f)' % ('SMOTE'+names[0],np.mean(T_n6),np.std(T_n6)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>B-acc</th>\n",
       "      <th>Train time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSVM</td>\n",
       "      <td>0.877220</td>\n",
       "      <td>2.192732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUSAdaboost</td>\n",
       "      <td>0.837818</td>\n",
       "      <td>3.721677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUSMLP</td>\n",
       "      <td>0.871758</td>\n",
       "      <td>2.552261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSBAG</td>\n",
       "      <td>0.844068</td>\n",
       "      <td>17.171235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTESVM</td>\n",
       "      <td>0.881043</td>\n",
       "      <td>49.882634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classifier     B-acc  Train time\n",
       "0       RUSSVM  0.877220    2.192732\n",
       "1  RUSAdaboost  0.837818    3.721677\n",
       "2       RUSMLP  0.871758    2.552261\n",
       "3       RUSBAG  0.844068   17.171235\n",
       "4     SMOTESVM  0.881043   49.882634"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>B-acc</th>\n",
       "      <th>Train time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSVM</td>\n",
       "      <td>0.962794</td>\n",
       "      <td>0.332750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUSAdaboost</td>\n",
       "      <td>0.946535</td>\n",
       "      <td>1.226062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUSMLP</td>\n",
       "      <td>0.968664</td>\n",
       "      <td>0.433503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSBAG</td>\n",
       "      <td>0.924168</td>\n",
       "      <td>2.491943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTESVM</td>\n",
       "      <td>0.960109</td>\n",
       "      <td>19.965381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classifier     B-acc  Train time\n",
       "0       RUSSVM  0.962794    0.332750\n",
       "1  RUSAdaboost  0.946535    1.226062\n",
       "2       RUSMLP  0.968664    0.433503\n",
       "3       RUSBAG  0.924168    2.491943\n",
       "4     SMOTESVM  0.960109   19.965381"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>B-acc</th>\n",
       "      <th>Train time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSVM</td>\n",
       "      <td>0.859717</td>\n",
       "      <td>0.307451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUSAdaboost</td>\n",
       "      <td>0.831822</td>\n",
       "      <td>1.404027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUSMLP</td>\n",
       "      <td>0.865586</td>\n",
       "      <td>1.043724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSBAG</td>\n",
       "      <td>0.833697</td>\n",
       "      <td>4.104577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTESVM</td>\n",
       "      <td>0.802533</td>\n",
       "      <td>32.842193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classifier     B-acc  Train time\n",
       "0       RUSSVM  0.859717    0.307451\n",
       "1  RUSAdaboost  0.831822    1.404027\n",
       "2       RUSMLP  0.865586    1.043724\n",
       "3       RUSBAG  0.833697    4.104577\n",
       "4     SMOTESVM  0.802533   32.842193"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Class solution_XX() is the algorithm based on Xiaohua,Xuan[2019], the improvement is that\n",
    "we add a parameter of \"penalty\".'''\n",
    "class solution_XX:\n",
    "    \n",
    "    \n",
    "    def __init__(self,penalty = None,Lambda = 0.03,a = 0.5,epochs = 200):\n",
    "        self.W = None\n",
    "        self.penalty = penalty\n",
    "        self.Lambda = Lambda\n",
    "        self.a = a\n",
    "        self.epochs =epochs\n",
    "        self.sigmoid = lambda x:1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def f_XX(self,X,Y):\n",
    "        if self.penalty=='l1':f=np.array([np.mean((self.sigmoid(np.dot(x,self.W))-y)**2 )+self.Lambda*np.sum(np.abs(self.W)) for x,y in zip(X,Y)])\n",
    "        elif self.penalty=='l2':f=np.array([np.mean((self.sigmoid(np.dot(x,self.W))-y)**2 )+self.Lambda*np.sum(self.W**2) for x,y in zip(X,Y)])#pre_Xtrain,pre_Ytrain\n",
    "        else:f=np.array([np.mean((self.sigmoid(np.dot(x,self.W))-y)**2 ) for x,y in zip(X,Y)])\n",
    "\n",
    "        return f         \n",
    "    def Gf_XX(self,X,Y):#To compute the Derivative matrix, the shape of which is N*2\n",
    "        if self.penalty=='l1':d=np.array([x.T.dot(0.02*(self.sigmoid(np.dot(x,self.W))-y)*self.sigmoid(np.dot(x,self.W))*(1-self.sigmoid(np.dot(x,self.W))))+self.Lambda*np.sign(self.W )for x,y in zip(X,Y)])\n",
    "        elif self.penalty=='l2':\n",
    "            d=np.array([x.T.dot(0.02*(self.sigmoid(np.dot(x,self.W))-y)*self.sigmoid(np.dot(x,self.W))*(1-self.sigmoid(np.dot(x,self.W))))+2*self.Lambda*self.W for x,y in zip(X,Y)])\n",
    "\n",
    "        else:d=np.array([x.T.dot(0.02*(self.sigmoid(np.dot(x,self.W))-y)*self.sigmoid(np.dot(x,self.W))*(1-self.sigmoid(np.dot(x,self.W)))) for x,y in zip(X,Y)])\n",
    "        return d\n",
    "    def direction_XX(self,X,Y):\n",
    "        gra=self.Gf_XX(X,Y)\n",
    "        p=matrix(gra.dot(gra.T),tc='d')\n",
    "        q=matrix(-self.f_XX(X,Y),tc='d')\n",
    "        G=matrix(np.diag(np.array([-1]*(Y.shape[0]))),tc='d')#N=20\n",
    "        h=matrix(np.array([[0]]*(Y.shape[0])),tc='d')\n",
    "        A=matrix([[1.0]]*(Y.shape[0]))\n",
    "        b=matrix([1.0])\n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(p,q,G,h,A,b)\n",
    "        t=np.array(sol['x'])\n",
    "        d= -(gra.T.dot(t))\n",
    "        return d.reshape((X_sample_XX_6.shape[-1],))\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        \n",
    "        call=[]\n",
    "        pre=[]\n",
    "        loss=[]\n",
    "        testloss=[]\n",
    "        np.random.seed(1324)\n",
    "        self.W=np.random.random((X_sample_XX_6.shape[-1],))*2-1\n",
    "\n",
    "        \n",
    "        for k in range(200):\n",
    "\n",
    "            d=self.direction_XX(X,Y)\n",
    "\n",
    "            if np.linalg.norm(d)//10**(-7) < 25:\n",
    "                break\n",
    "            sigma=0.8\n",
    "            f_1=np.max(self.f_XX(X,Y))\n",
    "            w=self.W\n",
    "            self.W=d*sigma+w\n",
    "            while np.max(self.f_XX(X,Y))>np.max(f_1):\n",
    "                sigma=sigma*0.8\n",
    "                self.W=d*sigma+w\n",
    "            self.W=d*sigma+w\n",
    "\n",
    "            \n",
    "    \n",
    "        return self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Return the performances of max-mean loss regression on five random trials'''\n",
    "def fivetrials_XX_T(X,y,model=solution_XX()):\n",
    "    pipeline = model\n",
    "    \n",
    "    bacc,T=list(),list()\n",
    "    \n",
    "\n",
    "    for train_index,test_index in cv.split(X, y):\n",
    "        \n",
    "        start=time.time()\n",
    "\n",
    "        pre_X,pre_Y=split(X[test_index],y[test_index])\n",
    "#         print(pre_X[0].shape)\n",
    "\n",
    "        w_x=pipeline.fit(pre_X,pre_Y)\n",
    "        end=time.time()\n",
    "\n",
    "        T.append(end-start)\n",
    "        prdict_y=pipeline.sigmoid(X[train_index].dot(w_x))\n",
    "        prdict_y[prdict_y>=0.5]=1\n",
    "        prdict_y[prdict_y<0.5]=0\n",
    "\n",
    "    \n",
    "        bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return bacc,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">max_mean loss:: Average Balanced_Acc: 0.850(0.008) \n",
      ">max_mean loss:: Average Training time: 2.040(0.230)\n"
     ]
    }
   ],
   "source": [
    "'''Add the result of max-mean loss regression to Table all_results_6'''\n",
    "result_XX_6= fivetrials_XX_T(X_sample_XX_6,y_sample_6)\n",
    "Bacc=result_XX_6[0]\n",
    "\n",
    "T_XX_6=result_XX_6[-1]\n",
    "\n",
    "print('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('max_mean loss:',np.mean(Bacc),np.std(Bacc)))\n",
    "\n",
    "print('>%s: Average Training time: %.3f(%.3f)' % ('max_mean loss:',np.mean(T_XX_6),np.std(T_XX_6)))\n",
    "metrics_names=['B-acc','Train time']\n",
    "metric_res = {'Classifier':'max-mean loss'}\n",
    "for name, value in zip(metrics_names, np.mean(result_XX_6,axis=1)):\n",
    "\n",
    "        metric_res[name] = value\n",
    "\n",
    "\n",
    "all_results_6.append(metric_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>B-acc</th>\n",
       "      <th>Train time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSVM</td>\n",
       "      <td>0.877220</td>\n",
       "      <td>2.192732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUSAdaboost</td>\n",
       "      <td>0.837818</td>\n",
       "      <td>3.721677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUSMLP</td>\n",
       "      <td>0.871758</td>\n",
       "      <td>2.552261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSBAG</td>\n",
       "      <td>0.844068</td>\n",
       "      <td>17.171235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTESVM</td>\n",
       "      <td>0.881043</td>\n",
       "      <td>49.882634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max-mean loss</td>\n",
       "      <td>0.850231</td>\n",
       "      <td>2.039936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classifier     B-acc  Train time\n",
       "0         RUSSVM  0.877220    2.192732\n",
       "1    RUSAdaboost  0.837818    3.721677\n",
       "2         RUSMLP  0.871758    2.552261\n",
       "3         RUSBAG  0.844068   17.171235\n",
       "4       SMOTESVM  0.881043   49.882634\n",
       "5  max-mean loss  0.850231    2.039936"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_results_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DRM(P) algorithm '''\n",
    "class Poly_close_solution:\n",
    "    def __init__(self,kernel='self._poly',penalty = None,gamma=1,degree = 2,coef0=0,alpha=1,beta=1):\n",
    "        self.W = None\n",
    "        self.penalty = penalty\n",
    "        self.d = degree\n",
    "        self.b = coef0\n",
    "        self.alpha=alpha\n",
    "        self.beta=beta\n",
    "        self.g=gamma\n",
    "        self.kernel=kernel\n",
    "        \n",
    "    def _poly(self,X_1,X_2):\n",
    "        return (self.g*(X_1.dot(X_2.T))+self.b)**self.d\n",
    "    def _rbf(self,x,y):\n",
    "        return np.exp(-self.g*np.sum((x[...,None,:]-y)**2,axis=2))\n",
    "\n",
    "    def poly_B_matrix(self,X,Y):\n",
    "        n=Y[Y==1].shape[0]\n",
    "        X_sample_split=np.array(np.split(X,np.array([X.shape[0]-n])))\n",
    "        B=np.zeros((X.shape[0],X.shape[0]))\n",
    "        I=0\n",
    "        for  m in X_sample_split:\n",
    "            I+=m.shape[0]\n",
    "            B[I-m.shape[0]:I,I-m.shape[0]:I]=eval(self.kernel+'(m,m)')/m.shape[0]\n",
    "        return B\n",
    "    \n",
    "    def K_x(self,X,x_t):\n",
    "        return eval(self.kernel+'(X,x_t)')\n",
    "    \n",
    "    def QplusBeta(self,X,Y):\n",
    "        s=time.time()\n",
    "        K=eval(self.kernel+'(X,X)')\n",
    "        H_p=np.diag(np.diagonal(K))\n",
    "        B_p=self.poly_B_matrix(X,Y)\n",
    "        Qplus_beta=K+self.alpha*(H_p-B_p)+np.diag([self.beta]*X.shape[0])\n",
    "        e=time.time()\n",
    "        return K,Qplus_beta\n",
    "    def fit(self,invQ,X,x_t):\n",
    "        \n",
    "        \n",
    "        W=invQ.dot(self.K_x(X,x_t))##求逆耗时\n",
    "        \n",
    "        return W.reshape(-1)\n",
    "    def delta_phi(self,K,invQ,X,Y,x_t,j):\n",
    "        \n",
    "        w=self.fit(invQ,X,x_t)\n",
    "        w_noty=w\n",
    "\n",
    "        w_y=np.zeros((X.shape[0]))\n",
    "        indice=np.argwhere(Y==j).reshape(-1)\n",
    "        w_noty[indice]=0\n",
    "        w_y[indice]=w[indice]\n",
    "        delta=np.dot(w_y,K.dot(w_y))+np.dot(w_noty,K.dot(w_noty))-2*np.dot(w_y,self.K_x(X,x_t))\n",
    "        return delta\n",
    "    def predict(self,K,invQ,X,Y,x_t):\n",
    "        delta=[]\n",
    "        for k in np.unique(Y):\n",
    "            delta.append(self.delta_phi(K,invQ,X,Y,x_t,k))\n",
    "        return np.argmin(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is prediction process of distribution-uncertain methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_(x,u):\n",
    "    return 1.0/(1.0+np.exp(-x-u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanuncertainty(x,n):\n",
    "    r=[]\n",
    "    for i in range(0,len(x)+1-n,n//10):\n",
    "        r.append(np.mean(x[i:i+n]))\n",
    "    return min(r),max(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Return the max-mean of training error'''\n",
    "def equa_m(x,n,r):\n",
    "    pre_in=(np.dot(x_tr,model_in.coef_.T)+model_in.intercept_).reshape(x_tr.shape[0],)\n",
    "    ini_err=y_tr-sigmoid_(pre_in,x)##ini_err is the predicted err of training set, based on LR\n",
    "\n",
    "    for k in range(ini_err.shape[0]):\n",
    "    \n",
    "        if y_tr[k]==1:\n",
    "            ini_err[k]=r*ini_err[k]\n",
    "\n",
    "    \n",
    "    return meanuncertainty(ini_err,n)[1]\n",
    "def equa_fivem(x,n,r,Mod,x_train,y_train):\n",
    "    pre_in=(np.dot(x_train,Mod.coef_.T)+Mod.intercept_).reshape(x_train.shape[0],)\n",
    "    \n",
    "    ini_err=y_train-sigmoid_(pre_in,x)##ini_err is the predicted err of training set, based on LR\n",
    "\n",
    "    for k in range(ini_err.shape[0]):\n",
    "        if y_train[k]==1:\n",
    "            ini_err[k]=r*ini_err[k]\n",
    "\n",
    "    \n",
    "    return meanuncertainty(ini_err,n)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We use 'evaluate_modelxh' to obtain the average performance in 5-fold cross-validation set, for fixed upper mean 'm' \"\"\"\n",
    "\n",
    "metrics_names_lr=['Balanced_acc','F2_score','Recall','Precision']\n",
    "def evaluate_model_lr(X,y,m,model=LogisticRegression()):\n",
    "    \n",
    "    bacc,f2,rec,pre=list(),list(),list(),list()\n",
    "    for train_index,test_index in cv.split(X,y):\n",
    "#                 X_resampled_smote,y_resampled_smote=SMOTE().fit_resample(X[train_index], y[train_index])\n",
    "                model.fit(X[train_index],y[train_index])\n",
    "                prob_y=sigmoid_((np.dot(X[test_index],model.coef_.T)+model.intercept_),m)\n",
    "                \n",
    "                \n",
    "                prdict_y=np.round(prob_y)\n",
    "                rec.append(recall_score(y[test_index],prdict_y))\n",
    "                pre.append(precision_score(y[test_index],prdict_y))\n",
    "                \n",
    "                bacc.append(balanced_accuracy_score(y[test_index],prdict_y))\n",
    "                f2.append(fbeta_score(y[test_index],prdict_y,beta=2))\n",
    " \n",
    "    return bacc,f2,rec,pre\n",
    "    \n",
    "\n",
    "           \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Return the Average performances of mean-uncertain LR'''\n",
    "metrics_names_lr=['Balanced_acc','F2_score','Recall','Precision']\n",
    "def Fivetrails_mean(k,X,y,n,model=LogisticRegression()):##pamrameter n symbols the optimal window_size selected by CV before\n",
    "\n",
    "    G_m,bacc,f2,rec,pre,T=list(),list(),list(),list(),list(),list()\n",
    "    for train_index,test_index in cv.split(X,y):\n",
    "                s_1=time.time()\n",
    "\n",
    "                model.fit(X[test_index],y[test_index])\n",
    "                \n",
    "                mean_u=fsolve(lambda x:equa_fivem(x,n,0.5*(k+1),model,X[test_index],y[test_index]),0.5 )\n",
    "                t_1=time.time()\n",
    "\n",
    "                print(\"optimal upper_mean by CV: %.3f \"%(mean_u))\n",
    "                prob_y=sigmoid_((np.dot(X[train_index],model.coef_.T)+model.intercept_).reshape(X[train_index].shape[0],),mean_u\n",
    "                             )\n",
    "                \n",
    "                \n",
    "                \n",
    "                prdict_y=np.round(prob_y)\n",
    "                print(classification_report(y[train_index],prdict_y))\n",
    "                rec.append(recall_score(y[train_index],prdict_y))\n",
    "                pre.append(precision_score(y[train_index],prdict_y))\n",
    "                G_m.append(np.sqrt(recall_score(y[train_index],prdict_y)*recall_score(y[train_index],prdict_y,pos_label=0)))\n",
    "                bacc.append(balanced_accuracy_score(y[train_index],prdict_y))\n",
    "                f2.append(fbeta_score(y[train_index],prdict_y,beta=max(2,np.log(k))))\n",
    "                T.append(t_1-s_1)\n",
    "    return G_m,bacc,f2,rec,pre,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal upper_mean by CV: 3.040 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.86      0.92     11012\n",
      "         1.0       0.53      0.89      0.67      1953\n",
      "\n",
      "    accuracy                           0.87     12965\n",
      "   macro avg       0.75      0.87      0.79     12965\n",
      "weighted avg       0.91      0.87      0.88     12965\n",
      "\n",
      "optimal upper_mean by CV: 2.751 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92     11013\n",
      "         1.0       0.55      0.91      0.68      1952\n",
      "\n",
      "    accuracy                           0.87     12965\n",
      "   macro avg       0.76      0.89      0.80     12965\n",
      "weighted avg       0.92      0.87      0.88     12965\n",
      "\n",
      "optimal upper_mean by CV: 2.726 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.88      0.93     11013\n",
      "         1.0       0.57      0.89      0.69      1953\n",
      "\n",
      "    accuracy                           0.88     12966\n",
      "   macro avg       0.77      0.89      0.81     12966\n",
      "weighted avg       0.92      0.88      0.89     12966\n",
      "\n",
      "optimal upper_mean by CV: 2.894 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92     11013\n",
      "         1.0       0.55      0.89      0.68      1953\n",
      "\n",
      "    accuracy                           0.88     12966\n",
      "   macro avg       0.77      0.88      0.80     12966\n",
      "weighted avg       0.91      0.88      0.89     12966\n",
      "\n",
      "optimal upper_mean by CV: 2.558 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.88      0.93     11013\n",
      "         1.0       0.57      0.88      0.69      1953\n",
      "\n",
      "    accuracy                           0.88     12966\n",
      "   macro avg       0.77      0.88      0.81     12966\n",
      "weighted avg       0.91      0.88      0.89     12966\n",
      "\n",
      ">LR_mean:: Average G-mean:0.881(0.005) \n",
      ">LR_mean:: Average Balanced_Acc: 0.881(0.005) \n",
      ">LR_mean:: Average Fbeta: 0.794(0.007)\n",
      ">LR_mean:: Average Recall: 0.890(0.010)\n",
      ">LR_mean:: Average Training time: 0.649(0.011)\n",
      ">LR_mean:: Average Score: 0.859(0.006)\n"
     ]
    }
   ],
   "source": [
    "result_6 = Fivetrails_mean(y_sample_6.shape[0]/sum(y_sample_6)-1,X_sample_6,y_sample_6,30)\n",
    "# \n",
    "G_mean=result_6[0]\n",
    "Bacc=result_6[1]\n",
    "# summarize performance\n",
    "recall=result_6[3]\n",
    "Fbeta=result_6[2]\n",
    "T_mean_6=result_6[-1]\n",
    "acc_s=np.mean(np.array(result_6)[:4,:],axis=0)\n",
    "\n",
    "print('>%s: Average G-mean:%.3f(%.3f) ' % ('LR_mean:',np.mean(G_mean),np.std(G_mean)))\n",
    "print('>%s: Average Balanced_Acc: %.3f(%.3f) ' % ('LR_mean:',np.mean(Bacc),np.std(Bacc)))\n",
    "print('>%s: Average Fbeta: %.3f(%.3f)' % ('LR_mean:',np.mean(Fbeta),np.std(Fbeta)))\n",
    "print('>%s: Average Recall: %.3f(%.3f)' % ('LR_mean:',np.mean(recall),np.std(recall)))\n",
    "print('>%s: Average Training time: %.3f(%.3f)' % ('LR_mean:',np.mean(T_mean_6),np.std(T_mean_6)))\n",
    "print('>%s: Average Score: %.3f(%.3f)' % ('LR_mean:',np.mean(0.99*acc_s+0.01/(np.array(result_6)[-1,:]/10*9+1)),np.std(0.99*acc_s+0.01/(np.array(result_6)[-1,:]/10*9+1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add the result of mean-uncertain LR to all_results_6.'''\n",
    "metrics_names=['B-acc','Train time']\n",
    "metric_res = {'Classifier':'LR-mean'}\n",
    "for name, value in zip(metrics_names, [np.mean(result_6,axis=1)[1],np.mean(result_6,axis=1)[-1]]):\n",
    "#             print(name, ': ', value)\n",
    "        metric_res[name] = value\n",
    "\n",
    "\n",
    "all_results_6.append(metric_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6=pd.DataFrame(all_results_6)\n",
    "df_16=pd.DataFrame(all_results_16)\n",
    "df_36=pd.DataFrame(all_results_36)\n",
    "df_6['Classifier']=np.append(np.array(df_6['Classifier'].iloc[:-1]),'mean-uncertain LR*')\n",
    "df_16['Classifier']=np.append(np.array(df_16['Classifier'].iloc[:-1]),'mean-uncertain LR*')\n",
    "df_36['Classifier']=np.append(np.array(df_36['Classifier'].iloc[:-1]),'mean-uncertain LR*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array\n",
      "  alpha: scalar or None\n",
      "  animated: bool\n",
      "  backgroundcolor: color\n",
      "  bbox: dict with properties for `.patches.FancyBboxPatch`\n",
      "  clip_box: `.Bbox`\n",
      "  clip_on: bool\n",
      "  clip_path: Patch or (Path, Transform) or None\n",
      "  color or c: color\n",
      "  contains: unknown\n",
      "  figure: `.Figure`\n",
      "  fontfamily or family: {FONTNAME, 'serif', 'sans-serif', 'cursive', 'fantasy', 'monospace'}\n",
      "  fontproperties or font or font_properties: `.font_manager.FontProperties` or `str` or `pathlib.Path`\n",
      "  fontsize or size: float or {'xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large'}\n",
      "  fontstretch or stretch: {a numeric value in range 0-1000, 'ultra-condensed', 'extra-condensed', 'condensed', 'semi-condensed', 'normal', 'semi-expanded', 'expanded', 'extra-expanded', 'ultra-expanded'}\n",
      "  fontstyle or style: {'normal', 'italic', 'oblique'}\n",
      "  fontvariant or variant: {'normal', 'small-caps'}\n",
      "  fontweight or weight: {a numeric value in range 0-1000, 'ultralight', 'light', 'normal', 'regular', 'book', 'medium', 'roman', 'semibold', 'demibold', 'demi', 'bold', 'heavy', 'extra bold', 'black'}\n",
      "  gid: str\n",
      "  horizontalalignment or ha: {'center', 'right', 'left'}\n",
      "  in_layout: bool\n",
      "  label: object\n",
      "  linespacing: float (multiple of font size)\n",
      "  math_fontfamily: str\n",
      "  multialignment or ma: {'left', 'right', 'center'}\n",
      "  path_effects: `.AbstractPathEffect`\n",
      "  picker: None or bool or float or callable\n",
      "  position: (float, float)\n",
      "  rasterized: bool\n",
      "  rotation: float or {'vertical', 'horizontal'}\n",
      "  rotation_mode: {None, 'default', 'anchor'}\n",
      "  sketch_params: (scale: float, length: float, randomness: float)\n",
      "  snap: bool or None\n",
      "  text: object\n",
      "  transform: `.Transform`\n",
      "  transform_rotates_text: bool\n",
      "  url: str\n",
      "  usetex: bool or None\n",
      "  verticalalignment or va: {'center', 'top', 'bottom', 'baseline', 'center_baseline'}\n",
      "  visible: bool\n",
      "  wrap: bool\n",
      "  x: float\n",
      "  y: float\n",
      "  zorder: float\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f873c3bc978>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x405 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Plot the results reported in all_results_6,all_results_16, all_results_36.'''\n",
    "\n",
    "marker=['s','^','2','d','+','x','.']\n",
    "fig=plt.figure(figsize=(8,5),dpi=81\n",
    "              )\n",
    "\n",
    "ax1=plt.subplot(131)\n",
    "c1,c2,c3=0,0,0\n",
    "for i in np.array(df_6):\n",
    "    \n",
    "    ax1.scatter(i[1],i[2],label=i[0],marker=marker[c1])\n",
    "    c1+=1\n",
    "plt.setp(ax1.get_xticklabels())\n",
    "plt.xlabel('Average B-acc',fontsize='small')\n",
    "plt.ylabel('Average training time',fontsize='small')\n",
    "plt.title('CelebA_6',fontsize='small')\n",
    "ax2=plt.subplot(132,sharey=ax1)\n",
    "for i in np.array(df_16):\n",
    "    ax2.scatter(i[1],i[2],label=i[0],marker=marker[c2])\n",
    "    c2+=1\n",
    "plt.xlabel('Average B-acc',fontsize='small')\n",
    "plt.title('CelebA_16',fontsize='small')\n",
    "ax3=plt.subplot(133,sharey=ax1)\n",
    "for i in np.array(df_36):\n",
    "    ax3.scatter(i[1],i[2],label=i[0],marker=marker[c3])\n",
    "    c3+=1\n",
    "plt.xlabel('Average B-acc',fontsize='small')\n",
    "plt.title('CelebA_36',fontsize='small')\n",
    "plt.legend(loc='upper right',fontsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>B-acc</th>\n",
       "      <th>Train time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUSSVM</td>\n",
       "      <td>0.859717</td>\n",
       "      <td>0.307451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUSAdaboost</td>\n",
       "      <td>0.831822</td>\n",
       "      <td>1.404027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RUSMLP</td>\n",
       "      <td>0.865586</td>\n",
       "      <td>1.043724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSBAG</td>\n",
       "      <td>0.833697</td>\n",
       "      <td>4.104577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTESVM</td>\n",
       "      <td>0.802533</td>\n",
       "      <td>32.842193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max-mean loss</td>\n",
       "      <td>0.828053</td>\n",
       "      <td>2.661506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean-uncertain LR*</td>\n",
       "      <td>0.890526</td>\n",
       "      <td>0.916499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier     B-acc  Train time\n",
       "0              RUSSVM  0.859717    0.307451\n",
       "1         RUSAdaboost  0.831822    1.404027\n",
       "2              RUSMLP  0.865586    1.043724\n",
       "3              RUSBAG  0.833697    4.104577\n",
       "4            SMOTESVM  0.802533   32.842193\n",
       "5       max-mean loss  0.828053    2.661506\n",
       "6  mean-uncertain LR*  0.890526    0.916499"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
